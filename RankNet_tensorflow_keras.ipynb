{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlf+UmEuJ2UworZ+nf+9a9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhisekh97/RankNet_tf_keras/blob/main/RankNet_tensorflow_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xO-PMIDUPpRZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, activations, losses, Model, Input\n",
        "from tensorflow.nn import leaky_relu\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "from tensorflow.keras.utils import plot_model, Progbar\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Model Architecture"
      ],
      "metadata": {
        "id": "FeZ8Pl5pTWVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RankNet(Model):\n",
        "  def __init__(self):\n",
        "    super().__init__(self)\n",
        "    self.dense = [layers.Dense(16, activation=leaky_relu), layers.Dense(8, activation=leaky_relu)]\n",
        "    self.o = layers.Dense(1, activation='linear')\n",
        "    self.oi_minus_oj = layers.Subtract()\n",
        "\n",
        "\n",
        "  def call(self, input):\n",
        "    xi , xj = input\n",
        "    densei = self.dense[0](xi)\n",
        "    densej = self.dense[0](xj)\n",
        "    for dense in self.dense[1:]:\n",
        "      densei = dense(densei)\n",
        "      densej = dense(densej)\n",
        "\n",
        "    oi = self.o(densei)\n",
        "    oj = self.o(densej)\n",
        "    oij = self.oi_minus_oj([oi, oj])\n",
        "    output = layers.Activation('sigmoid')(oij)\n",
        "    return output\n",
        "\n",
        "  def build_graph(self):\n",
        "    x = [Input(shape=(10)), Input(shape=(10))]\n",
        "    return Model(inputs=x, outputs=self.call(x))\n",
        "\n",
        "model = RankNet()\n",
        "model.build_graph().summary()\n"
      ],
      "metadata": {
        "id": "BGhZE8LnP5FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56c8ac22-670d-4871-a8dd-9d249f653fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 10)]                 0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 10)]                 0         []                            \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 16)                   176       ['input_1[0][0]',             \n",
            "                                                                     'input_2[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 8)                    136       ['dense[0][0]',               \n",
            "                                                                     'dense[1][0]']               \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 1)                    9         ['dense_1[0][0]',             \n",
            "                                                                     'dense_1[1][0]']             \n",
            "                                                                                                  \n",
            " subtract (Subtract)         (None, 1)                    0         ['dense_2[0][0]',             \n",
            "                                                                     'dense_2[1][0]']             \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 1)                    0         ['subtract[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 321 (1.25 KB)\n",
            "Trainable params: 321 (1.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_query = 20\n",
        "query = np.array([i+1 for i in range(nb_query) for x in range(int(np.ceil(np.abs(np.random.normal(0,scale=15))+2)))])\n",
        "query\n"
      ],
      "metadata": {
        "id": "rjrioqW2hHz6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "395ca59f-1f92-44da-a02c-ae2fdccc40d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
              "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,\n",
              "        3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
              "        4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
              "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
              "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,\n",
              "        8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,\n",
              "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
              "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
              "        9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11,\n",
              "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
              "       11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
              "       12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
              "       13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
              "       13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
              "       14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
              "       15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
              "       16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
              "       17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
              "       17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18,\n",
              "       19, 19, 19, 19, 20, 20, 20, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_features = np.random.random((len(query), 10))\n",
        "doc_features.shape"
      ],
      "metadata": {
        "id": "-1bRXryjEK8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_scores = np.random.randint(5, size=len(query)).astype(np.float32)\n",
        "doc_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5bQdFR-FRb2",
        "outputId": "9a76f21b-2ed7-4e9a-e796-64a725724fa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(399,)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMkeQ1pRGI7X",
        "outputId": "f11c136e-1dc9-4bc8-9ab7-04480f87c8ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4., 2., 3., 0., 0., 4., 3., 3., 1., 4., 2., 3., 2., 0., 3., 1., 2.,\n",
              "       1., 0., 1., 2., 4., 4., 0., 1., 1., 0., 3., 4., 2., 0., 2., 4., 0.,\n",
              "       3., 3., 2., 1., 4., 1., 4., 0., 1., 0., 2., 3., 1., 3., 4., 0., 1.,\n",
              "       3., 1., 1., 3., 1., 3., 0., 2., 3., 0., 3., 1., 0., 0., 3., 3., 2.,\n",
              "       0., 2., 0., 4., 1., 0., 4., 2., 1., 2., 3., 0., 0., 0., 0., 3., 3.,\n",
              "       2., 1., 2., 4., 0., 4., 3., 0., 1., 2., 3., 3., 3., 3., 0., 3., 1.,\n",
              "       4., 0., 2., 2., 1., 3., 2., 2., 4., 3., 0., 4., 1., 1., 0., 3., 4.,\n",
              "       2., 3., 0., 0., 1., 4., 1., 0., 4., 2., 0., 4., 2., 3., 3., 3., 0.,\n",
              "       1., 4., 4., 0., 1., 1., 1., 4., 2., 0., 0., 2., 3., 2., 0., 0., 3.,\n",
              "       4., 4., 3., 0., 1., 0., 0., 3., 0., 4., 2., 3., 4., 2., 2., 3., 0.,\n",
              "       4., 1., 3., 1., 4., 1., 4., 1., 3., 1., 2., 1., 3., 0., 1., 0., 4.,\n",
              "       3., 0., 1., 3., 4., 1., 3., 0., 3., 2., 0., 1., 1., 1., 2., 4., 3.,\n",
              "       3., 0., 1., 3., 2., 3., 4., 0., 2., 0., 4., 2., 0., 2., 4., 4., 1.,\n",
              "       4., 0., 4., 1., 2., 4., 0., 2., 0., 3., 0., 2., 4., 2., 2., 2., 4.,\n",
              "       4., 4., 0., 2., 4., 1., 2., 3., 4., 2., 4., 3., 0., 3., 1., 3., 1.,\n",
              "       4., 1., 4., 0., 0., 0., 4., 0., 2., 1., 3., 1., 2., 0., 2., 4., 0.,\n",
              "       2., 2., 3., 1., 1., 1., 4., 4., 3., 2., 3., 3., 4., 2., 4., 0., 2.,\n",
              "       0., 4., 3., 1., 0., 1., 2., 2., 0., 1., 1., 1., 2., 2., 2., 1., 0.,\n",
              "       4., 0., 3., 2., 4., 2., 4., 4., 4., 2., 3., 3., 4., 1., 4., 2., 4.,\n",
              "       4., 1., 3., 3., 3., 3., 2., 1., 2., 1., 3., 1., 4., 1., 3., 4., 3.,\n",
              "       1., 2., 0., 4., 4., 3., 1., 3., 2., 1., 2., 1., 4., 0., 1., 4., 2.,\n",
              "       1., 3., 2., 2., 3., 0., 3., 2., 2., 0., 4., 3., 2., 1., 1., 2., 3.,\n",
              "       1., 1., 0., 0., 4., 1., 2., 2., 0., 2., 4., 4., 3., 1., 4., 4., 2.,\n",
              "       3., 1., 0., 0., 0., 4., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So above features are doc_features which equals to the number of Query.\n",
        "so for each query there is one feature vector .\n",
        "target is basically score provided between 0 to 4 as good to bad relevance. 0 being very bad relevance and 4 being highly relevant items. These labels will be given by Human in practical Scenerio or will be collected from some Human interface as a click Stream Data.  "
      ],
      "metadata": {
        "id": "jLtVgWV5G4EJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xi = []\n",
        "xj = []\n",
        "pij = []\n",
        "pair_id = []\n",
        "pair_query_id = []\n",
        "for q in np.unique(query):\n",
        "  query_idx = np.where(query == q)[0]\n",
        "  for pair_idx in combinations(query_idx, 2):\n",
        "    # print(pair_idx)\n",
        "    pair_query_id.append(q)\n",
        "    pair_id.append(pair_idx)\n",
        "    i = pair_idx[0]\n",
        "    j = pair_idx[1]\n",
        "    xi.append(doc_features[i])\n",
        "    xj.append(doc_features[j])\n",
        "\n",
        "    if doc_scores[i] == doc_scores[j]:\n",
        "        _pij = 0.5\n",
        "    elif doc_scores[i] > doc_scores[j]:\n",
        "        _pij = 1\n",
        "    else:\n",
        "        _pij = 0\n",
        "    pij.append(_pij)\n"
      ],
      "metadata": {
        "id": "b4Dq5ondGlcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xi = np.array(xi)\n",
        "xj = np.array(xj)\n",
        "pij = np.array(pij)\n",
        "pair_query_id = np.array(pair_query_id)"
      ],
      "metadata": {
        "id": "H2-UfCxlH0cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xi_train, xi_test, xj_train, xj_test, pij_train, pij_test, pair_id_train, pair_id_test = train_test_split(\n",
        "    xi, xj, pij, pair_id, test_size=0.2, stratify=pair_query_id)"
      ],
      "metadata": {
        "id": "au-3-YdBprdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranknet = RankNet()"
      ],
      "metadata": {
        "id": "k2lZW7n9qIzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranknet.compile(optimizer = 'adam', loss = 'binary_crossentropy')"
      ],
      "metadata": {
        "id": "n3fQkwvBqTIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranknet.fit([xi_train, xj_train], pij_train , epochs=50, batch_size=1, validation_data=([xi_test, xj_test], pij_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iri2cPiWqb9x",
        "outputId": "88dade18-828c-46ac-8a9b-42741fdfaccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3984/3984 [==============================] - 12s 2ms/step - loss: 0.6845 - val_loss: 0.6790\n",
            "Epoch 2/50\n",
            "3984/3984 [==============================] - 10s 2ms/step - loss: 0.6717 - val_loss: 0.6688\n",
            "Epoch 3/50\n",
            "3984/3984 [==============================] - 9s 2ms/step - loss: 0.6596 - val_loss: 0.6555\n",
            "Epoch 4/50\n",
            "3984/3984 [==============================] - 9s 2ms/step - loss: 0.6485 - val_loss: 0.6459\n",
            "Epoch 5/50\n",
            "3984/3984 [==============================] - 9s 2ms/step - loss: 0.6348 - val_loss: 0.6346\n",
            "Epoch 6/50\n",
            "3984/3984 [==============================] - 8s 2ms/step - loss: 0.6215 - val_loss: 0.6292\n",
            "Epoch 7/50\n",
            "3984/3984 [==============================] - 9s 2ms/step - loss: 0.6123 - val_loss: 0.6181\n",
            "Epoch 8/50\n",
            "3984/3984 [==============================] - 9s 2ms/step - loss: 0.6002 - val_loss: 0.6165\n",
            "Epoch 9/50\n",
            "3984/3984 [==============================] - 10s 3ms/step - loss: 0.5926 - val_loss: 0.6094\n",
            "Epoch 10/50\n",
            "3984/3984 [==============================] - 9s 2ms/step - loss: 0.5826 - val_loss: 0.5974\n",
            "Epoch 11/50\n",
            "3984/3984 [==============================] - 11s 3ms/step - loss: 0.5742 - val_loss: 0.5868\n",
            "Epoch 12/50\n",
            "3984/3984 [==============================] - 9s 2ms/step - loss: 0.5662 - val_loss: 0.5816\n",
            "Epoch 13/50\n",
            "3984/3984 [==============================] - 10s 2ms/step - loss: 0.5588 - val_loss: 0.5731\n",
            "Epoch 14/50\n",
            "3984/3984 [==============================] - 10s 3ms/step - loss: 0.5520 - val_loss: 0.5821\n",
            "Epoch 15/50\n",
            "3984/3984 [==============================] - 9s 2ms/step - loss: 0.5452 - val_loss: 0.5671\n",
            "Epoch 16/50\n",
            "3984/3984 [==============================] - 9s 2ms/step - loss: 0.5378 - val_loss: 0.5564\n",
            "Epoch 17/50\n",
            "3984/3984 [==============================] - 10s 2ms/step - loss: 0.5320 - val_loss: 0.5688\n",
            "Epoch 18/50\n",
            "3984/3984 [==============================] - 10s 3ms/step - loss: 0.5254 - val_loss: 0.5601\n",
            "Epoch 19/50\n",
            "3984/3984 [==============================] - 9s 2ms/step - loss: 0.5192 - val_loss: 0.5478\n",
            "Epoch 20/50\n",
            "3984/3984 [==============================] - 10s 2ms/step - loss: 0.5158 - val_loss: 0.5388\n",
            "Epoch 21/50\n",
            "3984/3984 [==============================] - 10s 3ms/step - loss: 0.5107 - val_loss: 0.5374\n",
            "Epoch 22/50\n",
            "3984/3984 [==============================] - 10s 2ms/step - loss: 0.5051 - val_loss: 0.5353\n",
            "Epoch 23/50\n",
            "3984/3984 [==============================] - 10s 3ms/step - loss: 0.5003 - val_loss: 0.5403\n",
            "Epoch 24/50\n",
            "3984/3984 [==============================] - 9s 2ms/step - loss: 0.4951 - val_loss: 0.5286\n",
            "Epoch 25/50\n",
            "3984/3984 [==============================] - 10s 3ms/step - loss: 0.4928 - val_loss: 0.5227\n",
            "Epoch 26/50\n",
            "3984/3984 [==============================] - 10s 3ms/step - loss: 0.4866 - val_loss: 0.5480\n",
            "Epoch 27/50\n",
            "3984/3984 [==============================] - 10s 2ms/step - loss: 0.4851 - val_loss: 0.5470\n",
            "Epoch 28/50\n",
            "3984/3984 [==============================] - 10s 3ms/step - loss: 0.4849 - val_loss: 0.5120\n",
            "Epoch 29/50\n",
            "3984/3984 [==============================] - 9s 2ms/step - loss: 0.4794 - val_loss: 0.5036\n",
            "Epoch 30/50\n",
            "3984/3984 [==============================] - 10s 2ms/step - loss: 0.4786 - val_loss: 0.5123\n",
            "Epoch 31/50\n",
            "3984/3984 [==============================] - 10s 3ms/step - loss: 0.4761 - val_loss: 0.5020\n",
            "Epoch 32/50\n",
            "3984/3984 [==============================] - 10s 2ms/step - loss: 0.4721 - val_loss: 0.5038\n",
            "Epoch 33/50\n",
            "3984/3984 [==============================] - 11s 3ms/step - loss: 0.4701 - val_loss: 0.5032\n",
            "Epoch 34/50\n",
            "3984/3984 [==============================] - 9s 2ms/step - loss: 0.4695 - val_loss: 0.4942\n",
            "Epoch 35/50\n",
            "3984/3984 [==============================] - 10s 2ms/step - loss: 0.4650 - val_loss: 0.4958\n",
            "Epoch 36/50\n",
            "3984/3984 [==============================] - 10s 2ms/step - loss: 0.4652 - val_loss: 0.5002\n",
            "Epoch 37/50\n",
            "3984/3984 [==============================] - 10s 2ms/step - loss: 0.4629 - val_loss: 0.5150\n",
            "Epoch 38/50\n",
            "3984/3984 [==============================] - 10s 3ms/step - loss: 0.4554 - val_loss: 0.5181\n",
            "Epoch 39/50\n",
            "3984/3984 [==============================] - 9s 2ms/step - loss: 0.4610 - val_loss: 0.4929\n",
            "Epoch 40/50\n",
            "3984/3984 [==============================] - 10s 3ms/step - loss: 0.4548 - val_loss: 0.5046\n",
            "Epoch 41/50\n",
            "3984/3984 [==============================] - 10s 3ms/step - loss: 0.4553 - val_loss: 0.4844\n",
            "Epoch 42/50\n",
            "3984/3984 [==============================] - 10s 2ms/step - loss: 0.4540 - val_loss: 0.4902\n",
            "Epoch 43/50\n",
            "3984/3984 [==============================] - 9s 2ms/step - loss: 0.4510 - val_loss: 0.4873\n",
            "Epoch 44/50\n",
            "3984/3984 [==============================] - 9s 2ms/step - loss: 0.4474 - val_loss: 0.5304\n",
            "Epoch 45/50\n",
            "3984/3984 [==============================] - 10s 3ms/step - loss: 0.4493 - val_loss: 0.4856\n",
            "Epoch 46/50\n",
            "3984/3984 [==============================] - 10s 2ms/step - loss: 0.4445 - val_loss: 0.4908\n",
            "Epoch 47/50\n",
            "3984/3984 [==============================] - 10s 3ms/step - loss: 0.4470 - val_loss: 0.4967\n",
            "Epoch 48/50\n",
            "3984/3984 [==============================] - 9s 2ms/step - loss: 0.4439 - val_loss: 0.4828\n",
            "Epoch 49/50\n",
            "3984/3984 [==============================] - 10s 2ms/step - loss: 0.4400 - val_loss: 0.4731\n",
            "Epoch 50/50\n",
            "3984/3984 [==============================] - 10s 2ms/step - loss: 0.4390 - val_loss: 0.5016\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f1c8bdd5ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g8v8d3IDqwoz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}